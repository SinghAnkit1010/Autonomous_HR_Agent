{
    "qa_pairs": [
        [
            {
                "question": "What is the main task when using Vision Transformers (ViT) with images?",
                "choices": [
                    "A) Convert an image into pixels",
                    "B) Convert an image into sentences",
                    "C) Convert an image into patches",
                    "D) Convert an image into vectors"
                ],
                "answer": "C) Convert an image into patches"
            },
            {
                "question": "Why is the self-attention mechanism of Transformers leveraged in Vision Transformers (ViT)?",
                "choices": [
                    "A) To convert images into text",
                    "B) To process sequential data",
                    "C) To enhance image quality",
                    "D) To create pixel-based models"
                ],
                "answer": "B) To process sequential data"
            },
            {
                "question": "What is the purpose of patchifying the image in Vision Transformers (ViT)?",
                "choices": [
                    "A) To flatten each patch",
                    "B) To apply linear projection",
                    "C) To split the image into smaller patches",
                    "D) To resize the image"
                ],
                "answer": "C) To split the image into smaller patches"
            }
        ],
        [
            {
                "question": "What are some of the more advanced algorithms used in image segmentation?",
                "choices": [
                    "A) k-means, DBSCAN, hierarchical clustering",
                    "B) active contour, graph cuts, Markov conditional random fields",
                    "C) decision trees, random forests, gradient boosting",
                    "D) linear regression, logistic regression, SVM"
                ],
                "answer": "B) active contour, graph cuts, Markov conditional random fields"
            },
            {
                "question": "What are the limitations of traditional skin segmentation techniques using color thresholds?",
                "choices": [
                    "A) High accuracy, low computational cost",
                    "B) No false positive errors, robust to lighting conditions",
                    "C) False positive errors due to low light conditions and similar colored background objects",
                    "D) Easily adaptable to different color spaces"
                ],
                "answer": "C) False positive errors due to low light conditions and similar colored background objects"
            },
            {
                "question": "Which model-based machine learning technique is commonly used for skin segmentation?",
                "choices": [
                    "A) k-nearest neighbors",
                    "B) logistic regression",
                    "C) Bayesian classifier",
                    "D) decision tree"
                ],
                "answer": "C) Bayesian classifier"
            }
        ],
        [
            {
                "question": "What is the purpose of scaling the scores by the square root of the dimensionality of the key vectors in the self-attention mechanism?",
                "choices": [
                    "A) To reduce the computation complexity",
                    "B) To prevent the gradients from becoming too large during backpropagation",
                    "C) To increase the model's capacity for memorization",
                    "D) To speed up the learning process"
                ],
                "answer": "B) To prevent the gradients from becoming too large during backpropagation"
            },
            {
                "question": "Why is the softmax function applied to the scaled scores in the self-attention mechanism?",
                "choices": [
                    "A) To eliminate noise in the input sequence",
                    "B) To increase the model's accuracy",
                    "C) To normalize the scores into a probability distribution",
                    "D) To introduce non-linearity"
                ],
                "answer": "C) To normalize the scores into a probability distribution"
            },
            {
                "question": "What is the purpose of weighting the values using the attention weights in the self-attention mechanism?",
                "choices": [
                    "A) To introduce sparsity in the output vectors",
                    "B) To reduce the model's complexity",
                    "C) To compute a weighted sum enriched with contextual information",
                    "D) To decrease the interpretability of the word representations"
                ],
                "answer": "C) To compute a weighted sum enriched with contextual information"
            }
        ],
        [
            {
                "question": "What is the unique feature of masked multi-head attention in generating sequences?",
                "choices": [
                    "A. It focuses on future information",
                    "B. It only considers the preceding tokens",
                    "C. It concatenates all tokens",
                    "D. It disregards all tokens"
                ],
                "answer": "B. It only considers the preceding tokens"
            },
            {
                "question": "How does masked multi-head attention contribute to maintaining the integrity of sequential data processing?",
                "choices": [
                    "A. By looking at all tokens simultaneously",
                    "B. By peeking at future information",
                    "C. By focusing on the preceding tokens",
                    "D. By ignoring the input sequence"
                ],
                "answer": "C. By focusing on the preceding tokens"
            },
            {
                "question": "In what way does masked multi-head attention benefit tasks like machine translation and language modeling?",
                "choices": [
                    "A. By disregarding context",
                    "B. By predictively generating tokens",
                    "C. By ensuring logical flow and accuracy",
                    "D. By random token selection"
                ],
                "answer": "C. By ensuring logical flow and accuracy"
            }
        ],
        [
            {
                "question": "Which method is used to compute the similarity between the Query and the Key vectors?",
                "choices": [
                    "A) Cosine Similarity",
                    "B) Euclidean Distance",
                    "C) Pearson Correlation",
                    "D) Manhattan Distance"
                ],
                "answer": "A) Cosine Similarity"
            },
            {
                "question": "What range does the Cosine Similarity value vary between?",
                "choices": [
                    "A) 0 to 1",
                    "B) -1 to 1",
                    "C) 0 to -1",
                    "D) -1 to 0"
                ],
                "answer": "B) -1 to 1"
            },
            {
                "question": "Why do we need to convert textual data into numbers before feeding it into machine learning models?",
                "choices": [
                    "A) To reduce the size of data",
                    "B) To improve model visualization",
                    "C) To enable mathematical computations",
                    "D) To simplify the data processing steps"
                ],
                "answer": "C) To enable mathematical computations"
            }
        ],
        [
            {
                "question": "What is the purpose of the 'cls_token' in the PositionalEncoding class?",
                "choices": [
                    "A. To calculate the positional encoding values",
                    "B. To add to the beginning of each embedding",
                    "C. To expand the tokens batch",
                    "D. To create classification tokens"
                ],
                "answer": "B. To add to the beginning of each embedding"
            },
            {
                "question": "In the 'forward' method of the PositionalEncoding class, what does 'x = x + self.pe' achieve?",
                "choices": [
                    "A. Multiplying 'x' with positional encoding",
                    "B. Adding class tokens to 'x'",
                    "C. Substituting positional encoding to embeddings",
                    "D. Adding positional encoding to embeddings"
                ],
                "answer": "D. Adding positional encoding to embeddings"
            },
            {
                "question": "Why is the positional encoding calculated using sine and cosine functions in the PositionalEncoding class?",
                "choices": [
                    "A. To introduce randomness in position encoding",
                    "B. To simplify the calculations",
                    "C. To add diverse positional information",
                    "D. To create learnable positional embeddings"
                ],
                "answer": "C. To add diverse positional information"
            }
        ],
        [
            {
                "question": "Which method reduces overfitting by penalizing or adding a constraint to the loss function?",
                "choices": [
                    "A) Gradient Descent",
                    "B) Backpropagation",
                    "C) Weight Regularization",
                    "D) Activation Function"
                ],
                "answer": "C) Weight Regularization"
            },
            {
                "question": "What are the two types of weight regularization represented by L1 & L2?",
                "choices": [
                    "A) Minimize loss function & maximize error",
                    "B) Training error & testing error",
                    "C) Batch Gradient Descent & Stochastic Gradient Descent",
                    "D) L1 & L2"
                ],
                "answer": "D) L1 & L2"
            },
            {
                "question": "What is the impact of having a very small training error on the overall loss of the network?",
                "choices": [
                    "A) Increase the regularization term",
                    "B) Decrease the output value of the loss function",
                    "C) Increase the error gradient",
                    "D) Increase the predicted vs actual error"
                ],
                "answer": "B) Decrease the output value of the loss function"
            }
        ],
        [
            {
                "question": "Which method is recommended to make the model stable without affecting data quality and privacy?",
                "choices": [
                    "A) Data augmentation",
                    "B) Addition of noise to input data",
                    "C) Addition of noise to output data",
                    "D) Feature selection"
                ],
                "answer": "B) Addition of noise to input data"
            },
            {
                "question": "What is the purpose of adding noise to the output data?",
                "choices": [
                    "A) Make the model stable",
                    "B) Maintain data quality and privacy",
                    "C) Increase data diversity",
                    "D) Reduce overfitting"
                ],
                "answer": "C) Increase data diversity"
            },
            {
                "question": "Which method is considered less expensive and safer compared to training with more data?",
                "choices": [
                    "A) Data augmentation",
                    "B) Addition of noise to input data",
                    "C) Addition of noise to output data",
                    "D) Feature selection"
                ],
                "answer": "A) Data augmentation"
            }
        ],
        [
            {
                "question": "What is the purpose of Queries (Q) in the context of a model's processing of a sequence?",
                "choices": [
                    "A. Represent the entire sequence",
                    "B. Evaluate the relevance of each word in the sequence",
                    "C. Store contextual information",
                    "D. Determine the reference points"
                ],
                "answer": "B. Evaluate the relevance of each word in the sequence"
            },
            {
                "question": "How do Keys (K) contribute to the model's understanding of the relationship between words in a sequence?",
                "choices": [
                    "A. They represent the output values",
                    "B. They compare the query vector to the key vector",
                    "C. They generate contextual information",
                    "D. They construct the entire sequence"
                ],
                "answer": "B. They compare the query vector to the key vector"
            },
            {
                "question": "Which component in the model is responsible for holding the contextual information of each word in the sequence?",
                "choices": [
                    "A. Queries (Q)",
                    "B. Keys (K)",
                    "C. Values (V)",
                    "D. Reference points"
                ],
                "answer": "C. Values (V)"
            }
        ],
        [
            {
                "question": "What is the purpose of importing numpy in the given code snippet?",
                "choices": [
                    "Perform mathematical operations on the data",
                    "Visualize the data",
                    "Train the neural network model",
                    "Save the model weights"
                ],
                "answer": "Perform mathematical operations on the data"
            },
            {
                "question": "What is the role of PatchEmbedding class in the code snippet?",
                "choices": [
                    "Define the neural network architecture",
                    "Load the MNIST dataset",
                    "Perform data augmentation",
                    "Project image patches into a higher-dimensional space"
                ],
                "answer": "Project image patches into a higher-dimensional space"
            },
            {
                "question": "What does the flatten(2) operation do in the forward method of PatchEmbedding class?",
                "choices": [
                    "Reduce the dimensionality of the data",
                    "Calculate the gradient descent",
                    "Normalize the output",
                    "Reshape the tensor"
                ],
                "answer": "Reshape the tensor"
            }
        ],
        [
            {
                "question": "What is the purpose of putting a list of encoder layers inside a sequential wrapper in a transformer?",
                "choices": [
                    "A) To concatenate the encoder layers",
                    "B) To allow for multiple encoder modules",
                    "C) To speed up the model training process",
                    "D) To simplify the code implementation"
                ],
                "answer": "B) To allow for multiple encoder modules"
            },
            {
                "question": "What is the function of the MLP classification head in a vision transformer model?",
                "choices": [
                    "A) To split the image into patches",
                    "B) To add positional encoding to the image patches",
                    "C) To determine the classes of the images",
                    "D) To calculate attention scores between patches"
                ],
                "answer": "C) To determine the classes of the images"
            },
            {
                "question": "In the forward method of the vision transformer model, what is the purpose of passing the input images through the positional encoding layer?",
                "choices": [
                    "A) To reduce the dimensionality of the input images",
                    "B) To add a classification token to the image patches",
                    "C) To determine the attention weights between patches",
                    "D) To add positional information to the image patches"
                ],
                "answer": "D) To add positional information to the image patches"
            }
        ],
        [
            {
                "question": "What is the purpose of splitting an image into patches in Vision Transformer (ViT)?",
                "choices": [
                    "A. Improve color balance",
                    "B. Enhance resolution",
                    "C. Capture spatial information",
                    "D. Reduce file size"
                ],
                "answer": "C. Capture spatial information"
            },
            {
                "question": "How are patches in an image transformed into vectors in ViT?",
                "choices": [
                    "A. Stacking them vertically",
                    "B. Flattening them into vectors",
                    "C. Rotating them clockwise",
                    "D. Dividing them into equal parts"
                ],
                "answer": "B. Flattening them into vectors"
            },
            {
                "question": "Why is positional encoding necessary in the ViT model for processing images?",
                "choices": [
                    "A. To add colors to the patches",
                    "B. To indicate patch order",
                    "C. To apply image filters",
                    "D. To increase image contrast"
                ],
                "answer": "B. To indicate patch order"
            }
        ],
        [
            {
                "question": "What was the primary drawback of static word embeddings?",
                "choices": [
                    "A. Lack of accuracy",
                    "B. Limited contextual adaptability",
                    "C. Slow processing speed",
                    "D. Incompatibility with other models"
                ],
                "answer": "B. Limited contextual adaptability"
            },
            {
                "question": "How does self-attention differ from static embeddings in generating word representations?",
                "choices": [
                    "A. It uses predefined vectors",
                    "B. It adjusts word representations based on surrounding words",
                    "C. It ignores contextual information",
                    "D. It generates vectors randomly"
                ],
                "answer": "B. It adjusts word representations based on surrounding words"
            },
            {
                "question": "In what way do contextual embeddings improve the understanding of word meaning?",
                "choices": [
                    "A. They reduce efficiency",
                    "B. They limit model's capabilities",
                    "C. They adjust based on context, capturing true meaning",
                    "D. They create static representations"
                ],
                "answer": "C. They adjust based on context, capturing true meaning"
            }
        ],
        [
            {
                "question": "What is the purpose of semantic segmentation?",
                "choices": [
                    "A) Label countable objects",
                    "B) Label uncountable stuff",
                    "C) Label arbitrary object classes",
                    "D) Label complete scenes"
                ],
                "answer": "C) Label arbitrary object classes"
            },
            {
                "question": "Which segmentation technique combines both semantic and instance segmentation?",
                "choices": [
                    "A) Panoptic segmentation",
                    "B) Semantic segmentation",
                    "C) Instance segmentation",
                    "D) Complete segmentation"
                ],
                "answer": "A) Panoptic segmentation"
            },
            {
                "question": "What is the main difference between semantic and instance segmentation?",
                "choices": [
                    "A) Semantic segmentation labels countable objects",
                    "B) Instance segmentation labels uncountable stuff",
                    "C) Semantic segmentation labels arbitrary object classes",
                    "D) Instance segmentation labels each single object"
                ],
                "answer": "C) Semantic segmentation labels arbitrary object classes"
            }
        ],
        [
            {
                "question": "What should be passed as an argument to the model parameter in the trainer.train() function?",
                "choices": [
                    "model",
                    "training_args",
                    "train_dataset",
                    "tokenizer"
                ],
                "answer": "model"
            },
            {
                "question": "In the inference step using the fine-tuned model, what is the role of the feature extractor?",
                "choices": [
                    "Processing the input image",
                    "Displaying the predicted class",
                    "Calculating the evaluation metrics",
                    "Fine-tuning the model"
                ],
                "answer": "Processing the input image"
            },
            {
                "question": "What is the purpose of the torch.no_grad() context manager in the provided code snippet?",
                "choices": [
                    "Freezing the model parameters",
                    "Enabling gradient calculation",
                    "Disabling gradient calculation",
                    "Conducting model evaluation"
                ],
                "answer": "Disabling gradient calculation"
            }
        ]
    ]
}